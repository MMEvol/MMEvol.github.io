<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title> MMEvol </title>
  <link rel="icon" href="./static/images/logo.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">
  <link rel="stylesheet" href="./static/css/video-player.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/explorer-index.js"></script>
  <script src="./static/js/question_card.js"></script>

  <script src="./static/js/leaderboard_testmini.js"></script>  
  <script src="./data/results/output_folders.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>

  <script src="./visualizer/data/data_public.js" defer></script>

  <style>
    .no-sort {
        cursor: default;
        pointer-events: none;
        background-image: none !important; /* Remove the sort arrow */
    }
  </style>

</head>
<body>

  

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

      <div class="navbar-item has-dropdown is-hoverable">
        <p style="font-size:18px; display: inline; margin-right: -2px; margin-top: 12px;">üî•</p>
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
<!--           <a class="navbar-item" href="https://github.com/RainBowLuoCS/DEEM">
            <b>DEEM</b> 
          </a> -->
          <a class="navbar-item" href="https://github.com/MozerWang/Loong">
            <b>Loong</b> 
          </a>
          <a class="navbar-item" href="https://github.com/October2001/ProLong">
            <b>ProLong</b> 
          </a>
          <!-- <a class="navbar-item" href="https://github.com/BradyFU/Video-MME">
            <b>Video-MME</b> 
          </a>    -->
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="static/images/logo.png" style="width:1.8em;vertical-align: middle" alt="Logo"/>
            <span class="mmevol" style="vertical-align: middle;text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.5)">MMEvol</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle ", style="width: 100%;margin-bottom: 20px;">
            <strong>Empowering MLLMs with Evol-Instruct</strong>
          </h2>
          
          <div class="is-size-5 publication-authors", style="width: 100%; margin: 15px auto;", >
            <span class="author-block">Run Luo<sup style="color:#33ffd6;">1</sup><sup>,</sup><sup style="color:#9400D3">2</sup><sup>*</sup>,</span>
            <span class="author-block">Haonang Zhang<sup style="color:#ed4b82;">3</sup><sup>*</sup>,</span>
<!--             <span class="author-block"><a href="https://scholar.google.com/citations?user=x1EPTHAAAAAJ&hl=en" target="_blank">Longze Chen</a><sup style="color:#33ffd6;">1</sup><sup>,</sup><sup style="color:#9400D3">2</sup></sup><sup>*</sup>,</span> -->
            <span class="author-block">Longze Chen<sup style="color:#33ffd6;">1</sup><sup>,</sup><sup style="color:#9400D3">2</sup></sup><sup>*</sup>,</span>
            <span class="author-block">Ting-En Lin<sup style="color:#ed4b82">3</sup></sup><sup>*</sup>,</span>
            <span class="author-block">Xiong Liu<sup style="color:#ed4b82">3</sup>,</span>
            <span class="author-block">Yuchuan Wu<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Min Yang<sup style="color:#33ffd6">1</sup><sup>,</sup><sup style="color:#9400D3">2</sup><sup>‚Ä†</sup>,</span>
            <span class="author-block">Minzheng Wang<sup style="color:#9400D3">2</sup>,</span>
            <span class="author-block">Pengpeng Zeng<sup style="color:#ffac33">4</sup>,</span>
            <span class="author-block">Lianli Gao<sup style="color:#1a4ebf;">5</sup>,</span>
            <span class="author-block">Heng Tao Shen<sup style="color:#ffac33;">4</sup>,</span>
            <span class="author-block">Yunshui Li<sup style="color:#33ffd6;">1</sup><sup>,</sup><sup style="color:#9400D3">2</sup>,</span>
            <span class="author-block">Xiaobo Xia<sup style="color:#6fbf73;">6</sup>,</span>
            <span class="author-block">Fei Huang<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Jingkuan Song<sup style="color:#ffac33;">4</sup><sup>‚Ä†</sup>,</span>
            <span class="author-block">Yongbin Li<sup style="color:#ed4b82;">3</sup><sup>‚Ä†</sup>,</span>
        </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#33ffd6">1</sup>SIAT,</span>
            <span class="author-block"><sup style="color:#9400D3">2</sup>UCAS,</span>
            <span class="author-block"><sup style="color:#ed4b82">3</sup>Alibaba,</span>
            <span class="author-block"><sup style="color:#ffac33">4</sup>TJU,</span>
            <span class="author-block"><sup style="color:#1a4ebf">5</sup>Independent,</span>
            <span class="author-block"><sup style="color:#6fbf73">6</sup>USYD</span><br>
            <!-- <span class="paper-block"><b style="color:#f41c1c">ICLR 2024 Oral</b> (85 in 7304, 1.2%)</span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2409.05840"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="FIRST AUTHOR PERSONAL LINK"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="FIRST AUTHOR PERSONAL LINK"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-huggingface"></i> -->
                      <p style="font-size:18px">ü§ó</p>
                  </span>
                  <span>Dataset</span>
                </a>
              </span> 
              <!-- Leaderboard Link. -->
              <span class="link-block">
                <a href="FIRST AUTHOR PERSONAL LINK"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -5%;">Abstract</h2>
        <div class="content has-text-justified">
          The development of Multimodal Large Language Models (MLLMs) has seen significant advancements. However, the quantity and quality of multimodal instruction data have emerged as significant bottlenecks in their progress. Manually creating multimodal instruction data is both time-consuming and inefficient, posing challenges in producing instructions of high complexity. Moreover, distilling instruction data from black-box commercial models (e.g., GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains performance to that of these models. The challenge of curating diverse and complex instruction data remains substantial. We propose MMEvol, a novel multimodal instruction data evolution framework that combines fine-grained perception evolution, cognitive reasoning evolution, and interaction evolution. This iterative approach breaks through data quality bottlenecks to generate a complex and diverse image-text instruction dataset, thereby empowering MLLMs with enhanced capabilities. Beginning with an initial set of instructions, SEED-163K, we utilize MMEvol to systematically broadens the diversity of instruction types, integrates reasoning steps to enhance cognitive capabilities, and extracts detailed information from images to improve visual understanding and robustness. To comprehensively evaluate the effectiveness of our data, we train LLaVA-NeXT using the evolved data and conduct experiments across 13 vision-language tasks. Compared to the baseline trained with seed data, our approach achieves an average accuracy improvement of 3.1 points and reaches state-of-the-art (SOTA) performance on 9 of these tasks.
        </div>
        <div class="content has-text-centered" style = "margin-top: 5%;">
            <img src="static/images/overview.jpg" alt="teaser_tasks" width="80%"/>
            <p style="text-align: center;", class="mt-3">
              <strong> Overview of MMEvol</strong>: Instruction evolution and instruction elimination synergistically collaborate through multiple rounds to enhance the diversity and complexity of instruction data.
            </p>
          </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>


<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mathvista_other">
    <span class="mathvista_other" style="vertical-align: middle">Methodology</span>
  </h1>
  </div>
</section>
            
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Prompt Template</h2>
          <div class="content has-text-justified">
            <p style="text-align: center;", class="mt-3">
              <strong>The Prompt Template of Cognitive Reasoning Evolution, Interactive Evolution, Fine-grained Perceptual Evolution and Instruction Elimination.</strong>
            </p>
            <div class="box m-5">
              <!-- <div TODO: more pic> -->
              <div id="results-carousel" class="carousel results-carousel">  

                  <div class="content has-text-centered image-wrapper" >
                    <img src="static/images/FPE.jpg" style="width: 80%;"/>
                  </div>

                  <div class="content has-text-centered image-wrapper">
                    <img src="static/images/CRE.jpg" style="width: 80%;"/>              
                  </div>

                  <div class="content has-text-centered image-wrapper">
                    <img src="static/images/IE.jpg" style="width: 80%;"/>              
                  </div>

                  <div class="content has-text-centered image-wrapper">
                    <img src="static/images/IEE.jpg" style="width: 80%;"/>              
                  </div>

              </div>
              <div class="content has-text-centered" style = "margin-top: 5%;">
                <img src="static/images/evol_case.jpg" alt="teaser_tasks" width="80%"/>
                <p style="text-align: center;", class="mt-3">
                  <strong> Evolution Case</strong>: MMEvol continuously enhances instruction data complexity and diversity over evol-instruct. The sample is from SEED-163K. We mark fine-grained visual information in red, new instructions form in green, and longer reasoning steps in blue.
                </p>
              </div>
            </div>
          </div> 

        </div>
      </div>
    </div>

        
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <h2 class="title is-3" style="margin-top: 30px;">Instruction Diversity Comparison</h2>
          
            
          <div class="box m-5">
            <div class="content has-text-centered">
            <img src="static/images/instruction_diversity.jpg" alt="teaser_tasks" width="80%"/>
            <p style="text-align: center; margin-top:3%;margin-left: auto; margin-right: auto; width: 80%;"> 
              <strong>Task Categories</strong>: The root verbs (inner circle) and their top noun objects (outer circle) of the seed data in <strong>Left</strong> and the evolved data in <strong>Right</strong>. MMEvol can significantly enhance the diversity of instruction data.
            </p>
            </div>
          </div>

        </div>
      </div>
    </div>


    <div class="columns is-centered">
      <div class="container">
        <div class="content has-text-centered">
          <h2 class="title is-3">Fine-grained Visual Objects Comparison</h2>

          <div class="box m-5" >
            <div class="content has-text-centered">
              <img src="static/images/long_tail.jpg" alt="data-composition" style="max-width: 100%;"/>
              <p style="text-align: center; margin-left: auto; margin-top:1%;margin-right: auto; width: 80%;" >
                <strong>The long-tail distribution of 200 visual objects between seed and evolved data. </strong>: MMEvol significantly improves the long-tail distribution of visual objects in the seed data, providing more fine-grained visual information, thereby boosting the model's generalization ability and robustness against hallucinations.<br/>
              </p>
            </div>
          </div>

        </div>
      </div>
    </div>
    
    <div class="columns is-centered m-6">
        <div class="column is-full has-text-centered content">
          <h2 class="title is-3">Instruction Complexity and Difficulty Comparison</h2>
          <div class="box m-5">
            
            <div id="results-carousel" class="carousel results-carousel">  
            
              <div class="content has-text-centered image-wrapper">
                <img src="static/images/data_analysis_skill.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">(1) The skills length distribution between the seed data and our evolved data.</p>
              </div> 
            
              <div class="content has-text-centered image-wrapper">
                <img src="static/images/data_analysis_step.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">(2) The reasoning steps length distribution between the seed data and our evolved data.</p>
              </div>
  
              <div class="content has-text-centered image-wrapper">
                <img src="static/images/data_analysis_score.jpg" alt="" width="70%"/>
                <p style="margin-bottom: 30px;">(3) The difficulty and complexity level distribution between the seed data and our evolved data.</p>
              </div>

            </div>
  
            </div>
  
        </div>
      </div>

  </div>


</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista_other">Experiment Results</h1>
  </div>
</section>

<section class="section">
  <div class="container">

    <div class="columns is-centered">
      <div class="column has-text-centered content">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/table.png" alt="e" width="70%"/>
              <p style="text-align: center; margin-left: auto; margin-right: auto; width: 70%;" >
                <strong>
                  Comparison with state-of-the-art methods on 13 visual-language benchmarks
                </strong>:  
                 Our MMEvol consistently improve LLaVA-NeXT under a head-to-head comparison, using the same prompts and the same base LLM, showing the effectiveness of enhanced pretraining data quality. We mark the best performance bold and the second-best underlined. 
              </p>
            </div>
            <div class="content has-text-centered">
              <img src="static/images/qa_examples.jpg" alt="e" width="70%"/>
              <p style="text-align: center; margin-left: auto; margin-right: auto; width: 70%;" >
                <strong>
                  Examples of image-text dialogue with our Evol-8B MLLM
                </strong>:  
                 Our model trained on evolved data exhibits strong visual reasoning, instruction following, and fine-grained perception capabilities. Additionally, it identifies nuances in meme content, validating the effectiveness and efficiency of MMEvol.
              </p>
            </div>
          </div>       
      </div>
    </div>
  </div>
</section>


</section>
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mathvista_other" id="citation">Citation</h1>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <pre><code>
      @article{run2024mmevol,
      title={MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct},
      author={Run Luo, Haonan Zhang, Longze Chen, Ting-En Lin, Xiong Liu, Yuchuan Wu, Min Yang, Minzheng Wang, Pengpeng Zeng, Lianli Gao, Heng Tao Shen, Yunshui Li, Xiaobo Xia, Fei Huang, Jingkuan Song, Yongbin Li},
      journal={arXiv preprint arXiv:2409.05840},
      year={2024}
}      
</code></pre>
  </div>
</section>


<section class="section">
  <div class="container" style="width: 60%;">
  <style>
      pre {
        background-color: #f4f4f4;
        padding: 5px; /* Ë∞ÉÊï¥padding‰∏∫5px */
        border: 1px solid #ddd;
        border-radius: 5px;
        overflow-x: auto; /* ÂÖÅËÆ∏Ê∞¥Âπ≥ÊªöÂä® */
    }
    code {
        font-family: Consolas, "Courier New", monospace;
        color: #d63384; /* ‰ª£Á†ÅÊñáÊú¨È¢úËâ≤ */
    }
  </style>


  </div>
</section>


<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align: center;">
            This website is adapted from <a href="https://video-mme.github.io/">Video-MME</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->
</footer>

</body>
</html>
